# A01 Web scraper

1- I have structured my code in modules. I have the main file app.js and four modules. Everything starts at the main which only scrapes the first website to get the three different links and the call each module to scrape the specific link. I have a module to scrap the calendar, a module to scrape the cinema, and a module to scrape the restaurant website and finally, I have a module called result which gathers the information and present the final recommendations. I think a main with modules will best fit this kind of application because the job is divided and no single file has all the methods. 

2- In my opinion, one should first know how the asynchronous programming in Node.js works because it is essential and without understanding it the application will not work as intended. Promises or async and await functions are important to the workflow of the application. My advice is to build an application to learn because if you only learn it theoretically you will never face the special cases which sometimes have different solutions. 

3- I am satisfied with my application and of course it could be improved by handling more errors and structuring the code better. I like the way I handle promises in my application I have tried a lot of alternatives until I found the best way for my application. I think I have control over the flow of the application. 

4- I learned how asynchronous programming works using promises, and this is my biggest TIL of this assignment. I learned how to structure the code using modules. I learned about the cheerio and request modules for scraping websites. Cheerio has a lot of special syntaxes I learned many of them. I learned more about Node.js and. I am more confident with git and npm. 
